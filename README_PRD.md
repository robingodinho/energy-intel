# U.S. Energy Intelligence Platform â€” PRD & Build Guide
**Framework:** Next.js 14.x (DO NOT UPGRADE TO 15+)  
**Deployment:** Vercel  
**Purpose:** Highâ€‘performance, AIâ€‘powered regulatory intelligence platform for U.S. energy policy

---

## How to Use This Document (Important)

This README acts as the **single source of truth** for:
- Project scope and intent
- Architectural constraints
- Stepâ€‘byâ€‘step implementation order
- Task tracking for Claude Code

Claude Code should:
- Follow steps **sequentially**
- Update the task tracker as work is completed
- Respect **Next.js 14.x only**
- Avoid adding experimental or unnecessary features

---

## Product Vision

Build a **fast, reliable, and costâ€‘efficient** platform that:
- Aggregates U.S. federal energy policy updates (FERC, EPA, DOE, EIA)
- Uses AI **only during ingestion** (never at page load)
- Stores preâ€‘processed articles in a database
- Serves a clean, instantly loading feed to users

This is a **productionâ€‘grade system**, not a demo.

---

## Core Principles (Nonâ€‘Negotiable)

- âœ… Next.js **14.x only**
- âœ… No AI calls during page render
- âœ… Scheduled ingestion via Vercel Cron
- âœ… Databaseâ€‘backed storage (Supabase)
- âœ… Readâ€‘heavy, fast APIs
- âŒ No scraping arbitrary websites
- âŒ No experimental Next.js features
- âŒ No sidebars or Perplexity UI cloning (focus on function + speed)

---

## Highâ€‘Level Architecture

```
Official RSS Feeds (FERC, EPA, DOE, EIA)
        â†“
Scheduled Ingestion (Vercel Cron)
        â†“
AI Summarization + Categorization
        â†“
Supabase Postgres
        â†“
Readâ€‘Only API (/api/articles)
        â†“
Instant Frontend Feed
```

---

## Task Tracker

### ğŸ”„ In Progress
_Update this section as Claude Code works_

- [ ] Ready for next step: Step 11 (Integration + polish) or Step 12 (Deployment)

---

### âœ… Completed Tasks
_Check items off as they are finished_

- [x] Step 1: Project initialization (Next.js 14.x)
  - âœ“ Downgraded Next.js from 16.1.1 â†’ 14.2.35 (patched version, addresses security vulnerability)
  - âœ“ Downgraded React from 19.x â†’ 18.3.1
  - âœ“ Converted next.config.ts â†’ next.config.js (Next.js 14 compatibility)
  - âœ“ Updated Tailwind CSS from v4 â†’ v3.4.4 (v4 incompatible with Next.js 14)
  - âœ“ Created tailwind.config.js
  - âœ“ Updated postcss.config.mjs for Tailwind v3
  - âœ“ Updated globals.css with Tailwind v3 directives
  - âœ“ Updated layout.tsx (replaced Geist fonts with Inter for compatibility)
  - âœ“ Created .eslintrc.json (replaced flat config format)
- [x] Step 2: Environment configuration
  - âœ“ Created `env.template` with all required environment variables
  - âœ“ Verified .gitignore already covers `.env*` files
  - âœ“ Installed dependencies: rss-parser, openai, date-fns, @supabase/supabase-js
  - âœ“ User created `.env.local` with CRON_SECRET
- [x] Step 3: Cron configuration
  - âœ“ Created `app/api/ingest/route.ts` with security validation
  - âœ“ Endpoint validates `x-cron-secret` header OR `Authorization: Bearer <secret>`
  - âœ“ Returns 401 Unauthorized if secret doesn't match `CRON_SECRET` env var
  - âœ“ Uses `force-dynamic` to prevent caching
  - âœ“ Supports both GET (for Vercel Cron) and POST (for manual triggers)
  - âœ“ Created `vercel.json` with cron schedule: every 6 hours (`0 */6 * * *`)
  - **Note**: Full ingestion logic (RSS fetch, AI, DB) will be added in Steps 9-10
- [x] Step 4: Supabase database schema
  - âœ“ Created `lib/db.ts` with Supabase client singleton
  - âœ“ Uses lazy initialization to avoid build-time errors
  - âœ“ Added `insertArticles()` and `fetchArticles()` helpers
  - âœ“ Added `articleExists()` helper for deduplication checks
  - âœ“ Server-side only (no session persistence)
  - âœ“ User created `articles` table in Supabase
- [x] Step 5: TypeScript types
  - âœ“ Created `types/article.ts` with all article-related types
  - âœ“ `ArticleCategory` union: 'LNG' | 'Renewable Energy' | 'Energy Policy' | 'Emissions' | 'Infrastructure'
  - âœ“ `ArticleRow` matches DB schema exactly (snake_case field names)
  - âœ“ `ArticleInsert` omits auto-generated `created_at`
  - âœ“ `Article` alias for frontend use
  - âœ“ Added `RawFeedItem` and `FeedSource` types for RSS processing
  - âœ“ Updated `lib/db.ts` to import types from `@/types/article`
  - âœ“ Validated with `npm run build` â€” passes with no errors
- [x] Step 6: RSS feed configuration
  - âœ“ Created `lib/feeds.ts` with official government RSS sources
  - âœ“ 6 working feeds: EIA, DOE, Utility Dive, Renewable Energy World, Power Magazine, Energy Storage News
  - âœ“ 7 disabled feeds (access issues): FERC, EPA, Oil & Gas Journal, Reuters, S&P Global, IEA, IRENA
  - âœ“ Created `lib/fetchFeed.ts` with rss-parser, 15s timeout, dev diagnostics
  - âœ“ Created `lib/normalizeFeedItem.ts` for RawFeedItem â†’ PartialArticle conversion
  - âœ“ Stable ID generation: prefers guid, falls back to hash(link)
  - âœ“ Enhanced dev diagnostics: HTTP status, Content-Type, response preview
  - âœ“ Added `npm run test:feeds` with TEST_ALL and TEST_SOURCE options
  - âœ“ 111 total items across 6 sources
- [x] Step 6.5: Supabase database writes (implemented ahead of categorization)
  - âœ“ Created `lib/ingest.ts` with full ingestion pipeline
  - âœ“ Pipeline: fetch feeds â†’ normalize â†’ validate â†’ insert to Supabase
  - âœ“ Updated `/api/ingest` route to run full pipeline
  - âœ“ Duplicate handling: upsert with `ignoreDuplicates: true`
  - âœ“ Clear stats: inserted, duplicates, skipped, dbErrors
  - âœ“ Verified: 111 articles inserted on first run, 111 duplicates on second run
  - âœ“ Per-source breakdown in API response
- [x] Step 7: Categorization logic (keyword-based, deterministic)
  - âœ“ Created `lib/categorize.ts` with weighted keyword scoring
  - âœ“ 5 categories: LNG, Renewable Energy, Energy Policy, Emissions, Infrastructure
  - âœ“ Strong keywords (3 points) vs regular keywords (1 point)
  - âœ“ Fallback to "Energy Policy" for generic articles
  - âœ“ Updated `normalizeFeedItem.ts` to use categorization
  - âœ“ Created `/api/recategorize` endpoint to update existing articles
  - âœ“ Ran recategorization: 30 Renewable Energy, 22 Infrastructure, 59 Energy Policy
- [x] Step 8: Discover Feed UI (Perplexity-inspired)
  - âœ“ Created `lib/getArticles.ts` for server-side Supabase queries
  - âœ“ Created `lib/images.ts` for category â†’ placeholder image mapping
  - âœ“ Created 6 SVG placeholders in `/public/placeholders/` (one per category + default)
  - âœ“ Created `components/ArticleCard.tsx` with square image, title, summary, metadata
  - âœ“ Created `components/CategoryChips.tsx` (client component for URL-based filtering)
  - âœ“ Updated `app/page.tsx` with Discover layout: header, hero, grid, filters
  - âœ“ Dark mode styling with Tailwind, line-clamp, hover effects
  - âœ“ Responsive grid: 1/2/3/4 columns for mobile/tablet/desktop
  - âœ“ Category filtering via URL query params (`?category=LNG`)
  - âœ“ Build passes, UI renders with real Supabase data
- [x] Step 9: OpenGraph Image Enrichment
  - âœ“ Created `migrations/001_add_image_url.sql` â€” run in Supabase SQL Editor
  - âœ“ Updated `ArticleRow` and `ArticleInsert` types with `image_url?: string | null`
  - âœ“ Created `lib/scrapeImage.ts` â€” enhanced multi-fallback image scraper:
    - OpenGraph (og:image) and Twitter Card meta tags
    - JSON-LD Schema.org image extraction
    - Featured image patterns (WordPress, article images)
    - Fallback to first substantial img tag
  - âœ“ Created `app/api/enrich-images/route.ts` â€” protected enrichment endpoint
  - âœ“ Scrapes 15 articles per run, updates DB with found image URLs
  - âœ“ Updated `next.config.js` with `images.remotePatterns` for external URLs
  - âœ“ Updated `ArticleCard.tsx` with SVG-aware image handling and fallback
  - âœ“ Added cron to `vercel.json`: `/api/enrich-images` runs every 2 hours
  - âœ“ Added `force-dynamic` to `page.tsx` to prevent stale data caching
  - âœ“ All 107+ articles enriched with real cover images
- [x] Step 10: AI summarization logic
  - âœ“ Created `lib/summarize.ts` with OpenAI integration (gpt-4o-mini)
  - âœ“ Professional system prompt focused on energy policy analysis
  - âœ“ 2-3 sentence summaries highlighting compliance, market impacts, deadlines
  - âœ“ Updated `lib/ingest.ts` to summarize NEW articles only (cost-efficient)
  - âœ“ Checks for existing articles before summarizing to avoid duplicates
  - âœ“ Tracks summarization stats (attempted, successful, failed, tokens)
  - âœ“ Created `/api/resummarize` endpoint for existing articles
  - âœ“ Fallback to title-based summary if OpenAI fails
  - âœ“ All 111 articles successfully summarized (~30K tokens, ~$0.02)
- [ ] Step 11: Integration + polish
- [ ] Step 12: Deployment to Vercel

---

## Implementation Steps (Claude Code Must Follow)

### STEP 1 â€” Project Initialization
- Create Next.js project pinned to **14.2.0**
- Verify `package.json`:
```json
{
  "next": "14.2.0",
  "react": "^18",
  "react-dom": "^18"
}
```

---

### STEP 2 â€” Environment Variables
Create `.env.local`:
```env
OPENAI_API_KEY=...
OPENAI_MODEL=gpt-4o-mini

SUPABASE_URL=...
SUPABASE_ANON_KEY=...

CRON_SECRET=...
```

---

### STEP 3 â€” Vercel Cron
Create `vercel.json`:
```json
{
  "crons": [
    {
      "path": "/api/ingest",
      "schedule": "0 */6 * * *"
    }
  ]
}
```

---

### STEP 4 â€” Database Schema (Supabase)

Single table: `articles`

```sql
CREATE TABLE IF NOT EXISTS articles (
  id TEXT PRIMARY KEY,
  title TEXT NOT NULL,
  summary TEXT NOT NULL,
  link TEXT NOT NULL,
  pub_date TIMESTAMP NOT NULL,
  source TEXT NOT NULL,
  category TEXT NOT NULL,
  created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_articles_pub_date ON articles(pub_date DESC);
CREATE INDEX idx_articles_category ON articles(category);
```

---

### STEP 5 â€” TypeScript Types
File: `types/article.ts`

```ts
export interface Article {
  id: string;
  title: string;
  summary: string;
  link: string;
  pubDate: string;
  source: string;
  category:
    | 'LNG'
    | 'Renewable Energy'
    | 'Energy Policy'
    | 'Emissions'
    | 'Infrastructure';
}
```

---

### STEP 6 â€” RSS Feeds
File: `lib/feeds.ts`

Only official government sources. No scraping.

---

### STEP 7 â€” Categorization Logic
File: `lib/categorize.ts`

Keywordâ€‘based, deterministic. AI **not used** for categorization.

---

### STEP 8 â€” AI Summarization
File: `lib/summarize.ts`

Rules:
- 2â€“3 sentences
- Compliance + energy security focus
- Runs **only during ingestion**

---

### STEP 9 â€” Ingestion Logic
File: `lib/ingest.ts`

Must:
- Deduplicate articles
- Handle partial failures
- Return ingestion stats

---

### STEP 10 â€” Ingestion API
File: `app/api/ingest/route.ts`

- Protected by `CRON_SECRET`
- `force-dynamic`
- No caching

---

### STEP 11 â€” Articles API
File: `app/api/articles/route.ts`

- Readâ€‘only
- Cached (5 min)
- Supports category filtering

---

### STEP 12 â€” Article Card
File: `components/ArticleCard.tsx`

- Lightweight
- Responsive
- No heavy client logic

---

### STEP 13 â€” Main Page
File: `app/page.tsx`

- Fast initial load
- Filter tabs
- Grid layout
- Loading states

---

### STEP 14 â€” Initial Ingestion
Manually trigger:
```bash
curl http://localhost:3000/api/ingest
```

Verify data appears in Supabase.

---

### STEP 15 â€” Deployment
- Push to GitHub
- Import into Vercel
- Set env vars
- Verify cron runs

---

## Performance Targets

- Page load: < 2s
- API latency: < 500ms
- Ingestion run: < 5 min
- Monthly cost: < $15

---

## Security Notes

- `CRON_SECRET` required
- Env vars never committed
- Optional: Supabase RLS

---

## Definition of Success

- Platform loads instantly
- AI cost is predictable
- Articles update on schedule
- Codebase is clean and reviewable
- Architecture clearly demonstrates AI + data engineering competence

---

**END OF PRD & BUILD GUIDE**
